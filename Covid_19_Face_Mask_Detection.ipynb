{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid_19_Face_Mask_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "m8YtQCtQyrxq",
        "d0410JRuhB6U",
        "cgbFKjPNM2UF",
        "_s8RnmP0bN-L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kvnptl/Face-Mask-Detection-Using-Google-Colab/blob/master/Covid_19_Face_Mask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deF91mf0YjW3",
        "colab_type": "text"
      },
      "source": [
        "**Mount Google drive to colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nabMFpJCiEVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76c08248-c17d-4580-9fc3-4bc049ac60bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeh9fFJNictQ",
        "colab_type": "text"
      },
      "source": [
        "#**Step 3: UnZip face-mask-detector.zip**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij7XsORvibmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/face-mask-detector.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/My Drive/')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTxOhS8brv3q",
        "colab_type": "text"
      },
      "source": [
        "#Step 4: Change directory to face-mask-detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fXlb1_Xo46M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88359f2e-1e8d-49a1-ef7a-276f36945875"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/face-mask-detector"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/face-mask-detector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBvwaNKaouFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "231a82e7-8dd7-4fb7-e535-6cbf77e0c0c7"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/face-mask-detector'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECQdqCO-Ytx8",
        "colab_type": "text"
      },
      "source": [
        "#**Step 5: Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7HzGdw7onVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2fcd18b-aed9-4752-b4d4-531dea540eed"
      },
      "source": [
        "!python train_mask_detector.py --dataset dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-17 06:49:01.778187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "[INFO] loading images...\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "tcmalloc: large alloc 2315722752 bytes == 0x91922000 @  0x7f000c1a21e7 0x7f00089be5e1 0x7f0008a22c78 0x7f0008a25db8 0x7f0008a26395 0x7f0008abd65d 0x50a7f5 0x50cfd6 0x507f24 0x50b053 0x634dd2 0x634e87 0x63863f 0x6391e1 0x4b0dc0 0x7f000bd9fb97 0x5b26fa\n",
            "tcmalloc: large alloc 1852096512 bytes == 0x11b9cc000 @  0x7f000c1a21e7 0x7f00089be5e1 0x7f0008a22c78 0x7f0008a22d93 0x7f0008aaded6 0x7f0008aae338 0x50c4de 0x507f24 0x509c50 0x50a64d 0x50cfd6 0x507f24 0x509c50 0x50a64d 0x50c1f4 0x58e809 0x4c9306 0x588114 0x58834e 0x5517c1 0x5a9eec 0x50a783 0x50c1f4 0x507f24 0x509c50 0x50a64d 0x50cfd6 0x507f24 0x50b053 0x634dd2 0x634e87\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "2020-08-17 06:49:23.808909: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-17 06:49:23.874052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:23.874639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-17 06:49:23.874681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 06:49:24.110395: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-17 06:49:24.218198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-17 06:49:24.272499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-17 06:49:24.543930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-17 06:49:24.570239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-17 06:49:25.064202: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-17 06:49:25.064412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:25.065104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:25.065625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-17 06:49:25.081203: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-08-17 06:49:25.081437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1cc2a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-17 06:49:25.081481: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-17 06:49:25.218964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:25.219680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1cc39c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-17 06:49:25.219707: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-17 06:49:25.220678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:25.221195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-17 06:49:25.221244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 06:49:25.221297: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-17 06:49:25.221320: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-17 06:49:25.221342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-17 06:49:25.221362: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-17 06:49:25.221382: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-17 06:49:25.221403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-17 06:49:25.221495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:25.222033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:25.222568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-17 06:49:25.229031: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 06:49:29.063839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-17 06:49:29.063905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-17 06:49:29.063921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-17 06:49:29.068587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:29.069561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 06:49:29.070071: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-17 06:49:29.070119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "[INFO] compiling model...\n",
            "[INFO] training head...\n",
            "Epoch 1/20\n",
            "2020-08-17 06:49:33.077702: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-17 06:49:34.546550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "96/96 [==============================] - 32s 329ms/step - loss: 0.3598 - accuracy: 0.8380 - val_loss: 0.0988 - val_accuracy: 0.9831\n",
            "Epoch 2/20\n",
            "96/96 [==============================] - 31s 322ms/step - loss: 0.1120 - accuracy: 0.9609 - val_loss: 0.0606 - val_accuracy: 0.9896\n",
            "Epoch 3/20\n",
            "96/96 [==============================] - 30s 317ms/step - loss: 0.0896 - accuracy: 0.9694 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
            "Epoch 4/20\n",
            "96/96 [==============================] - 30s 317ms/step - loss: 0.0798 - accuracy: 0.9717 - val_loss: 0.0441 - val_accuracy: 0.9909\n",
            "Epoch 5/20\n",
            "96/96 [==============================] - 30s 315ms/step - loss: 0.0662 - accuracy: 0.9767 - val_loss: 0.0416 - val_accuracy: 0.9909\n",
            "Epoch 6/20\n",
            "96/96 [==============================] - 30s 318ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.0361 - val_accuracy: 0.9922\n",
            "Epoch 7/20\n",
            "96/96 [==============================] - 30s 315ms/step - loss: 0.0550 - accuracy: 0.9790 - val_loss: 0.0340 - val_accuracy: 0.9922\n",
            "Epoch 8/20\n",
            "96/96 [==============================] - 30s 316ms/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.0343 - val_accuracy: 0.9909\n",
            "Epoch 9/20\n",
            "96/96 [==============================] - 30s 315ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.0298 - val_accuracy: 0.9922\n",
            "Epoch 10/20\n",
            "96/96 [==============================] - 30s 314ms/step - loss: 0.0349 - accuracy: 0.9895 - val_loss: 0.0301 - val_accuracy: 0.9922\n",
            "Epoch 11/20\n",
            "96/96 [==============================] - 30s 313ms/step - loss: 0.0380 - accuracy: 0.9885 - val_loss: 0.0305 - val_accuracy: 0.9909\n",
            "Epoch 12/20\n",
            "96/96 [==============================] - 30s 312ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.0291 - val_accuracy: 0.9922\n",
            "Epoch 13/20\n",
            "96/96 [==============================] - 30s 311ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0285 - val_accuracy: 0.9935\n",
            "Epoch 14/20\n",
            "96/96 [==============================] - 30s 313ms/step - loss: 0.0276 - accuracy: 0.9901 - val_loss: 0.0274 - val_accuracy: 0.9922\n",
            "Epoch 15/20\n",
            "96/96 [==============================] - 30s 312ms/step - loss: 0.0349 - accuracy: 0.9885 - val_loss: 0.0285 - val_accuracy: 0.9909\n",
            "Epoch 16/20\n",
            "96/96 [==============================] - 30s 312ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0254 - val_accuracy: 0.9935\n",
            "Epoch 17/20\n",
            "96/96 [==============================] - 30s 312ms/step - loss: 0.0289 - accuracy: 0.9878 - val_loss: 0.0252 - val_accuracy: 0.9922\n",
            "Epoch 18/20\n",
            "96/96 [==============================] - 30s 311ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0290 - val_accuracy: 0.9922\n",
            "Epoch 19/20\n",
            "96/96 [==============================] - 30s 315ms/step - loss: 0.0257 - accuracy: 0.9924 - val_loss: 0.0287 - val_accuracy: 0.9935\n",
            "Epoch 20/20\n",
            "96/96 [==============================] - 30s 310ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.0242 - val_accuracy: 0.9935\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   with_mask       0.99      1.00      0.99       384\n",
            "without_mask       1.00      0.99      0.99       386\n",
            "\n",
            "    accuracy                           0.99       770\n",
            "   macro avg       0.99      0.99      0.99       770\n",
            "weighted avg       0.99      0.99      0.99       770\n",
            "\n",
            "[INFO] saving mask detector model...\n",
            "Traceback (most recent call last):\n",
            "  File \"train_mask_detector.py\", line 149, in <module>\n",
            "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
            "KeyError: 'acc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8YtQCtQyrxq",
        "colab_type": "text"
      },
      "source": [
        "#**Predict on Single Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JemeauwhjdY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# USAGE\n",
        "# Give input image file path (check other paths also)\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "from natsort import natsorted, ns\n",
        "\n",
        "input_file_path = \"/content/drive/My Drive/face-mask-detector/examples/example_01.png\"\n",
        "\n",
        "# load our serialized face detector model from disk\n",
        "print(\"[INFO] loading face detector model...\")\n",
        "prototxtPath = \"/content/drive/My Drive/face-mask-detector/face_detector/deploy.prototxt\"\n",
        "weightsPath = \"/content/drive/My Drive/face-mask-detector/face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "\n",
        "# load the face mask detector model from disk\n",
        "print(\"[INFO] loading face mask detector model...\")\n",
        "model = load_model(\"mask_detector.model\")\n",
        "\n",
        "def process_images(input_file_path):\n",
        "\t# load the input image from disk, clone it, and grab the image spatial\n",
        "  # dimensions\n",
        "\timage = cv2.imread(input_file_path)\n",
        "\t# orig = image.copy()\n",
        "\t(h, w) = image.shape[:2]\n",
        "\n",
        "\t# construct a blob from the image\n",
        "\tblob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "\t\t(104.0, 177.0, 123.0))\n",
        "\n",
        "\t# pass the blob through the network and obtain the face detections\n",
        "\tprint(\"[INFO] computing face detections...\")\n",
        "\tnet.setInput(blob)\n",
        "\tdetections = net.forward()\n",
        "\n",
        "\t# loop over the detections\n",
        "\tfor i in range(0, detections.shape[2]):\n",
        "\t\t# extract the confidence (i.e., probability) associated with\n",
        "\t\t# the detection\n",
        "\t\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t\t# filter out weak detections by ensuring the confidence is\n",
        "\t\t# greater than the minimum confidence\n",
        "\t\tif confidence > 0.5:\n",
        "\t\t\t# compute the (x, y)-coordinates of the bounding box for\n",
        "\t\t\t# the object\n",
        "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t\t# ensure the bounding boxes fall within the dimensions of\n",
        "\t\t\t# the frame\n",
        "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t\t# extract the face ROI, convert it from BGR to RGB channel\n",
        "\t\t\t# ordering, resize it to 224x224, and preprocess it\n",
        "\t\t\tface = image[startY:endY, startX:endX]\n",
        "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\t\tface = img_to_array(face)\n",
        "\t\t\tface = preprocess_input(face)\n",
        "\t\t\tface = np.expand_dims(face, axis=0)\n",
        "\n",
        "\t\t\t# pass the face through the model to determine if the face\n",
        "\t\t\t# has a mask or not\n",
        "\t\t\t(mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "\t\t\t# determine the class label and color we'll use to draw\n",
        "\t\t\t# the bounding box and text\n",
        "\t\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "\t\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "\n",
        "\t\t\t# include the probability in the label\n",
        "\t\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "\t\t\t# display the label and bounding box rectangle on the output\n",
        "\t\t\t# frame\n",
        "\t\t\tcv2.putText(image, label, (startX, startY - 10),\n",
        "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "\t\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "\t# show the output image\n",
        "\tsave_path = input_file_path.split(\".\",1)\n",
        "\t# print (save_path[0])\n",
        "\t# print (save_path[-1])\n",
        "\tcv2_imshow(image)\n",
        "\t# cv2.imwrite(save_path[0] + \"_pred.\" + save_path[-1],image)\n",
        "\n",
        "#start the process\n",
        "process_images(input_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0410JRuhB6U",
        "colab_type": "text"
      },
      "source": [
        "#**Predict on Multiple Images and make a MP4 video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "poqfh97Sg-pY",
        "colab": {}
      },
      "source": [
        "# USAGE\n",
        "# Give input images directory and output store directory\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "from natsort import natsorted, ns\n",
        "\n",
        "# input_file_path = \"/content/drive/My Drive/my_projects/face_mask_detector/testSet/pic7.jpg\"\n",
        "input_folder_path = \"/content/drive/My Drive/face-mask-detector/examples/\"\n",
        "output_folder_path = \"/content/drive/My Drive/face-mask-detector/test_OUTPUT.mp4\"\n",
        "\n",
        "# load our serialized face detector model from disk\n",
        "print(\"[INFO] loading face detector model...\")\n",
        "prototxtPath = \"/content/drive/My Drive/face-mask-detector/face_detector/deploy.prototxt\"\n",
        "weightsPath = \"/content/drive/My Drive/face-mask-detector/face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "\n",
        "# load the face mask detector model from disk\n",
        "print(\"[INFO] loading face mask detector model...\")\n",
        "model = load_model(\"mask_detector.model\")\n",
        "\n",
        "img_array = []\n",
        "\n",
        "def process_images(input_file_path,count):\n",
        "\t# load the input image from disk, clone it, and grab the image spatial\n",
        "  # dimensions\n",
        "\timage = cv2.imread(input_file_path)\n",
        "\torig = image.copy()\n",
        "\t(h, w) = image.shape[:2]\n",
        "\n",
        "\t# construct a blob from the image\n",
        "\tblob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "\t\t(104.0, 177.0, 123.0))\n",
        "\n",
        "\t# pass the blob through the network and obtain the face detections\n",
        "\t# print(\"[INFO] computing face detections...\")\n",
        "\tnet.setInput(blob)\n",
        "\tdetections = net.forward()\n",
        "\t\n",
        "\n",
        "\t# loop over the detections\n",
        "\tfor i in range(0, detections.shape[2]):\n",
        "\t\t# extract the confidence (i.e., probability) associated with\n",
        "\t\t# the detection\n",
        "\t\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t\t# filter out weak detections by ensuring the confidence is\n",
        "\t\t# greater than the minimum confidence\n",
        "\t\tif confidence > 0.5:\n",
        "\t\t\t# compute the (x, y)-coordinates of the bounding box for\n",
        "\t\t\t# the object\n",
        "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t\t# ensure the bounding boxes fall within the dimensions of\n",
        "\t\t\t# the frame\n",
        "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t\t# extract the face ROI, convert it from BGR to RGB channel\n",
        "\t\t\t# ordering, resize it to 224x224, and preprocess it\n",
        "\t\t\tface = image[startY:endY, startX:endX]\n",
        "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\t\tface = img_to_array(face)\n",
        "\t\t\tface = preprocess_input(face)\n",
        "\t\t\tface = np.expand_dims(face, axis=0)\n",
        "\n",
        "\t\t\t# pass the face through the model to determine if the face\n",
        "\t\t\t# has a mask or not\n",
        "\t\t\t(mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "\t\t\t# determine the class label and color we'll use to draw\n",
        "\t\t\t# the bounding box and text\n",
        "\t\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "\t\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "\n",
        "\t\t\t# include the probability in the label\n",
        "\t\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "\t\t\t# display the label and bounding box rectangle on the output\n",
        "\t\t\t# frame\n",
        "\t\t\tcv2.putText(image, label, (startX, startY - 10),\n",
        "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\t\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 5)\n",
        "\n",
        "\t# show the output image\n",
        "\t\n",
        "\t# cv2_imshow(image)\n",
        "\theight, width, layers = image.shape\n",
        "\tsize = (width,height)\n",
        "\timg_array.append(image)\n",
        "\t# resized_frame = cv2.resize(image, (400, 225))\n",
        "\tcount+=1\n",
        "\t# video.write(resized_frame)\n",
        "\tprint (\"\\r[INFO] Count: {}\".format(count),end='')\n",
        "\treturn size, count\n",
        "\t# cv2.imwrite(save_path,image)\n",
        "\n",
        "#start the process\n",
        "x = os.listdir(input_folder_path)\n",
        "sorted_path = natsorted(x, key=lambda y: y.lower())\n",
        "count = 0\n",
        "print (\"[INFO] Total files: {}\".format(len(x)))\n",
        "for k in sorted_path: \n",
        " file_path = input_folder_path + k\n",
        " print (\"\\r[INFO] File name: {}\".format(file_path))\n",
        " size, count = process_images(file_path,count)\n",
        "\n",
        "print (\"\\n[INFO] Total count/frames: {}\".format(count))\n",
        "\n",
        "#Saving all output frames as MP4 video\n",
        "print (\"[INFO] Saving video\")\n",
        "video = cv2.VideoWriter(output_folder_path, cv2.VideoWriter_fourcc(*'DIVX'), 1, size)\n",
        " \n",
        "for i in range(len(img_array)):\n",
        "    video.write(img_array[i])\n",
        "video.release()\n",
        "print (\"[INFO] process complete.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZwHKA9Gy1Fw",
        "colab_type": "text"
      },
      "source": [
        "#**Predict Using Video frames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDZgSIxAncAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0e98c2ee-9695-4c3d-fc87-2762b0f32e47"
      },
      "source": [
        "# USAGE\n",
        "# python detect_mask_video.py\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils.video import VideoStream\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "from imutils.video import FPS\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pdb\n",
        "\n",
        "#Input video file path\n",
        "input_video_path = \"/content/drive/My Drive/Myface2.mp4\"\n",
        "\n",
        "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
        "\t# grab the dimensions of the frame and then construct a blob\n",
        "\t# from it\n",
        "\t(h, w) = frame.shape[:2]\n",
        "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (200, 200),\n",
        "\t\t(104.0, 177.0, 123.0))\n",
        "\n",
        "\t# pass the blob through the network and obtain the face detections\n",
        "\tfaceNet.setInput(blob)\n",
        "\tdetections = faceNet.forward()\n",
        "\n",
        "\t# initialize our list of faces, their corresponding locations,\n",
        "\t# and the list of predictions from our face mask network\n",
        "\tfaces = []\n",
        "\tlocs = []\n",
        "\tpreds = []\n",
        "\n",
        "\t# loop over the detections\n",
        "\tfor i in range(0, detections.shape[2]):\n",
        "\t\t# extract the confidence (i.e., probability) associated with\n",
        "\t\t# the detection\n",
        "\t\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t\t# filter out weak detections by ensuring the confidence is\n",
        "\t\t# greater than the minimum confidence\n",
        "\t\tif confidence > 0.5:\n",
        "\t\t\t# compute the (x, y)-coordinates of the bounding box for\n",
        "\t\t\t# the object\n",
        "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t\t# ensure the bounding boxes fall within the dimensions of\n",
        "\t\t\t# the frame\n",
        "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t\t# extract the face ROI, convert it from BGR to RGB channel\n",
        "\t\t\t# ordering, resize it to 224x224, and preprocess it\n",
        "\t\t\tface = frame[startY:endY, startX:endX]\n",
        "\t\t\t#face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\t\tface = img_to_array(face)\n",
        "\t\t\tface = preprocess_input(face)\n",
        "\t\t\tface = np.expand_dims(face, axis=0)\n",
        "\n",
        "\t\t\t# add the face and bounding boxes to their respective\n",
        "\t\t\t# lists\n",
        "\t\t\tfaces.append(face)\n",
        "\t\t\tlocs.append((startX, startY, endX, endY))\n",
        "\n",
        "\t# only make a predictions if at least one face was detected\n",
        "\tif len(faces) > 0:\n",
        "\t\t# for faster inference we'll make batch predictions on *all*\n",
        "\t\t# faces at the same time rather than one-by-one predictions\n",
        "\t\t# in the above `for` loop\n",
        "\t\tpreds = maskNet.predict(faces)\n",
        "\n",
        "\t# return a 2-tuple of the face locations and their corresponding\n",
        "\t# locations\n",
        "\treturn (locs, preds)\n",
        "\n",
        "# load our serialized face detector model from disk\n",
        "print(\"[INFO] loading face detector model...\")\n",
        "prototxtPath = \"/content/drive/My Drive/face-mask-detector/face_detector/deploy.prototxt\"\n",
        "weightsPath = \"/content/drive/My Drive/face-mask-detector/face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "\n",
        "# load the face mask detector model from disk\n",
        "print(\"[INFO] loading face mask detector model...\")\n",
        "maskNet = load_model(\"mask_detector.model\")\n",
        "\n",
        "# initialize the video stream and allow the camera sensor to warm up\n",
        "print(\"[INFO] starting video stream...\")\n",
        "file_path = input_video_path.split(\".\",1)\n",
        "vs = cv2.VideoCapture(input_video_path)\n",
        "length = int(vs.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "time.sleep(2.0)\n",
        "\n",
        "#checking video available or not\n",
        "grabbed, frame_flip = vs.read()\n",
        "if not(grabbed): print (\"INPUT VIDEO NOT FOUND!\")\n",
        "\n",
        "# loop over the frames from the video stream\n",
        "count = 0\n",
        "img_array = []\n",
        "while grabbed:\n",
        "\t(grabbed, frame) = vs.read()\n",
        "\tif not(grabbed): break\n",
        "\tif (count==0): print (\"[INFO] processing started...\")\n",
        "\tframe = imutils.resize(frame, width=400)\n",
        "  \n",
        "\t#Optional step (comment if not needed)\n",
        "\tframe = cv2.rotate(frame, cv2.ROTATE_180)\n",
        "\t\n",
        "\t(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
        "\n",
        "\t# loop over the detected face locations and their corresponding\n",
        "\t# locations\n",
        "\tfor (box, pred) in zip(locs, preds):\n",
        "\t\t# unpack the bounding box and predictions\n",
        "\t\t(startX, startY, endX, endY) = box\n",
        "\t\t(mask, withoutMask) = pred\n",
        "\n",
        "\t\t# determine the class label and color we'll use to draw\n",
        "\t\t# the bounding box and text\n",
        "\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "\n",
        "\t\t# include the probability in the label\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "\t\t# display the label and bounding box rectangle on the output\n",
        "\t\t# frame\n",
        "\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "\t\n",
        "\t# cv2_imshow(frame)\n",
        "\theight, width, layers = frame.shape\n",
        "\tsize = (width,height)\n",
        "\timg_array.append(frame)\n",
        "\tprint (\"\\r[INFO] Count: {}/{}\".format(count, length),end='')\n",
        "\tcount+=1\n",
        "\n",
        "#Saving all output frames as MP4 video\n",
        "print (\"\\n[INFO] Saving video\")\n",
        "video = cv2.VideoWriter(file_path[0] + \"_OUTPUT.\" + file_path[-1], cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
        " \n",
        "for i in range(len(img_array)):\n",
        "    video.write(img_array[i])\n",
        "video.release()\n",
        "print (\"[INFO] process complete.\")\n",
        "\n",
        "# vs.stop()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading face detector model...\n",
            "[INFO] loading face mask detector model...\n",
            "[INFO] starting video stream...\n",
            "[INFO] processing started...\n",
            "[INFO] Count: 944/946\n",
            "[INFO] Saving video\n",
            "[INFO] process complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgbFKjPNM2UF",
        "colab_type": "text"
      },
      "source": [
        "#**Extract images from video (VIDEO -> IMAGES)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uijKwcJiLomI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "# Opens the Video file\n",
        "cap= cv2.VideoCapture('/content/drive/My Drive/test_vid.mp4')\n",
        "i = 0\n",
        "j = 0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    # frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite('/content/drive/My Drive/face-mask-detector/examples/testImg/test_image_'+str(i)+'.jpg',frame)\n",
        "    print (\"\\rCount: {}\".format(i),end='')\n",
        "    j+=1\n",
        "    i+=1\n",
        "\n",
        "# print (\"\\n[INFO] Next frame start with: {}\".format(i))\n",
        "print (\"\\n[INFO] Total frames: {}\".format(j))\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s8RnmP0bN-L",
        "colab_type": "text"
      },
      "source": [
        "#**Make a movie from images (IMAGES -> VIDEO)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ0RYaZ0PEig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ad099be8-9d6f-4b05-9588-8dedce12771e"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import pdb\n",
        "\n",
        "input_folder_path = '/content/drive/My Drive/face-mask-detector/examples/testImg/'\n",
        "\n",
        "#natural sorting\n",
        "x = os.listdir(input_folder_path)\n",
        "sorted_path = natsorted(x, key=lambda y: y.lower())\n",
        "length = len(sorted_path)\n",
        "count = 0\n",
        "img_array = []\n",
        "# for filename in glob.glob():\n",
        "for filename in sorted_path:\n",
        "    file_path = input_folder_path + filename\n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.rotate(img, cv2.ROTATE_180)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    img_array.append(img)\n",
        "    print (\"\\r[INFO] Count: {}/{}\".format(count, length),end='')\n",
        "    count+=1\n",
        "\n",
        "#Saving all output frames as MP4 video\n",
        "print (\"\\n[INFO] Saving video\")\n",
        "out = cv2.VideoWriter('/content/drive/My Drive/face-mask-detector/examples/testImg_OUTPUT.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
        " \n",
        "for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "out.release()\n",
        "print (\"[INFO] process complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Count: 290/291\n",
            "[INFO] Saving video\n",
            "[INFO] process complete.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}